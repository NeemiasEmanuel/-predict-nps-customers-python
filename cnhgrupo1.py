# -*- coding: utf-8 -*-
"""CNHGrupo1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yN2QGMJYuTLTDPxmVLoTGVcr3xMhcxrR
"""

from google.colab import files
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn import metrics
from sklearn.inspection import partial_dependence, PartialDependenceDisplay

uploaded = files.upload()

"""#Funções

"""

from google.colab import drive
drive.mount('/content/drive')

def gerar_curva_roc(y_test, y_proba, model_name):
    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba)
    roc_auc = metrics.auc(fpr, tpr)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve ({model_name}, AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'Receiver Operating Characteristic ({model_name})')
    plt.legend(loc="lower right")
    plt.show()

def gerarPDP(modelo, X_train, features, top_n=5):
    """
    Gera gráficos PDP (Partial Dependence Plots) para as variáveis mais importantes.

    Args:
        modelo: Modelo treinado (como RandomForestClassifier).
        X_train: Conjunto de dados de treinamento (DataFrame ou matriz).
        features: Lista de variáveis de entrada (colunas do DataFrame de entrada).
        top_n: Número de variáveis mais importantes para exibir (default: 5).

    Returns:
        None. Apenas exibe os gráficos PDP.
    """

    importances = modelo.feature_importances_
    indices = np.argsort(importances)[::-1][:top_n]
    top_features = [features[i] for i in indices]

    print(f"\nTop {top_n} variáveis mais importantes para PDP:")
    for i, feature in enumerate(top_features):
        print(f"{i+1}. {feature} - Importância: {importances[indices[i]]:.4f}")

    # Gerar gráficos PDP para cada variável
    for feature in top_features:
        plt.figure(figsize=(8, 6))
        PartialDependenceDisplay.from_estimator(modelo, X_train, [feature], grid_resolution=50)
        plt.title(f"PDP para {feature}")
        plt.show()

def criarSafra(regiao_df):
    return {

    2022: regiao_df[regiao_df['data_resposta'].dt.year == 2022],
    2023: regiao_df[regiao_df['data_resposta'].dt.year == 2023],
    2024: regiao_df[regiao_df['data_resposta'].dt.year == 2024]
}

def mostrarSafra(safra):


  print("\n### SAFRA 2022 ###\n")

  print(safra[2022][['data_resposta', 'nota', 'categoria']])

  print("\n### SAFRA 2023 ###\n")

  print(safra[2023][['data_resposta', 'nota', 'categoria']])

  print("\n### SAFRA 2024 ###\n")

  print(safra[2024][['data_resposta', 'nota', 'categoria']])


def criarModelo(df_modelo):

  numeric_filtered_df = df_modelo.select_dtypes(include=['number'])

  df_modelo['target_detractor'] = np.where(df_modelo['nota'] <= 6, 1, 0)
  df_modelo['target_neutral'] = np.where((df_modelo['nota'] > 6) & (df_modelo['nota'] <= 8), 1, 0)

  features_df = numeric_filtered_df.drop(columns=['nota'], errors='ignore')
  feature_names = features_df.columns


  target_detractor = df_modelo['target_detractor'].values


  target_neutral = df_modelo['target_neutral'].values


  X_train_detractor, X_test_detractor, y_train_detractor, y_test_detractor = train_test_split(features_df, target_detractor, test_size=0.3, random_state=42)


  model_detractor = RandomForestClassifier(random_state=42)
  model_detractor.fit(X_train_detractor, y_train_detractor)


  y_pred_detractor = model_detractor.predict(X_test_detractor)
  accuracy_detractor = accuracy_score(y_test_detractor, y_pred_detractor)
  y_detractor_proba = model_detractor.predict_proba(X_test_detractor)



  X_train_neutral, X_test_neutral, y_train_neutral, y_test_neutral = train_test_split(features_df, target_neutral, test_size=0.3, random_state=42)

  model_neutral = RandomForestClassifier(random_state=42)
  model_neutral.fit(X_train_neutral, y_train_neutral)
  y_neutral_proba = model_neutral.predict_proba(X_test_neutral)

  y_pred_neutral = model_neutral.predict(X_test_neutral)
  accuracy_neutral = accuracy_score(y_test_neutral, y_pred_neutral)


  print("\nAcurácia do modelo de detratores: {:.2f}".format(accuracy_detractor))
  print("\nProbabilidades previstas pelo modelo de detratores (primeiros 5 exemplos):")
  for i, probs in enumerate(y_detractor_proba[:5]):
    print(f"P {i+1}: Classe 0 (Não Detrator): {probs[0]:.2f}, Classe 1 (Detrator): {probs[1]:.2f}")


  print("\nAcurácia do modelo de neutros: {:.2f}".format(accuracy_neutral))
  print("\nProbabilidades previstas pelo modelo de neutros (primeiros 5 exemplos):")
  for i, probs in enumerate(y_neutral_proba[:5]):
    print(f"Probalidade {i+1}: Classe 0 (Não Neutro): {probs[0]:.2f}, Classe 1 (Neutro): {probs[1]:.2f}")


  cm = confusion_matrix(y_test_detractor, y_pred_detractor)

  TN, FP, FN, TP = cm.ravel()

  plt.figure(figsize=(8, 6))
  ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])

  plt.text(1.25, 1.25, f'TP={TP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
  plt.text(0.25, 0.25, f'TN={TN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='white', weight='bold')
  plt.text(0.25, 1.25, f'FP={FP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
  plt.text(1.25, 0.25, f'FN={FN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')

  plt.xlabel('Previsto')
  plt.ylabel('Verdadeiro')
  plt.title('Matriz de Confusão Detractor')
  plt.show()

  accuracyDetractor = accuracy_score(y_test_detractor, y_pred_detractor)
  print(f"Accuracy Detractor: {accuracyDetractor:.4f}")

  precisionDetractor = precision_score(y_test_detractor, y_pred_detractor)
  print(f"Precision Detractor: {precisionDetractor:.4f}")

  recallDetractor = recall_score(y_test_detractor, y_pred_detractor)
  print(f"Recall Detractor: {recallDetractor:.4f}")

  f1Detractor = f1_score(y_test_detractor, y_pred_detractor)
  print(f"F1-Score Detractor: {f1Detractor:.4f}")


  gerar_curva_roc(y_test_detractor, y_detractor_proba[:, 1], "Detratores")
  print("\n\n\n")

  cmNeutral = confusion_matrix(y_test_neutral, y_pred_neutral)

  TN, FP, FN, TP = cmNeutral.ravel()

  plt.figure(figsize=(8, 6))
  ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])

  plt.text(1.25, 1.25, f'TP={TP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
  plt.text(0.25, 0.25, f'TN={TN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='white', weight='bold')
  plt.text(0.25, 1.25, f'FP={FP}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')
  plt.text(1.25, 0.25, f'FN={FN}', horizontalalignment='center', verticalalignment='center', fontsize=12, color='black', weight='bold')

  plt.xlabel('Previsto')
  plt.ylabel('Verdadeiro')
  plt.title('Matriz de Confusão Neutral')
  plt.show()

  accuracyNeutral = accuracy_score(y_test_neutral, y_pred_neutral)
  print(f"Accuracy Neutral: {accuracyNeutral:.4f}")

  precisionNeutral = precision_score(y_test_neutral, y_pred_neutral)
  print(f"Precision Neutral: {precisionNeutral:.4f}")

  recallNeutral = recall_score(y_test_neutral, y_pred_neutral)
  print(f"Recall Neutral: {recallNeutral:.4f}")

  f1Neutral = f1_score(y_test_neutral, y_pred_neutral)
  print(f"F1-Score Neutral: {f1Neutral:.4f}")


  gerar_curva_roc(y_test_neutral, y_neutral_proba[:, 1], "Neutros")
  print("\n\n\n")

  importances_detractor = model_detractor.feature_importances_
  indices_detractor = np.argsort(importances_detractor)[::-1][:10]
  top_10_features_detractor = features_df.columns[indices_detractor]
  print("\nTop 10 variáveis mais importantes para o modelo de detratores:")
  for i, feature in enumerate(top_10_features_detractor):
    print(f"{i + 1}. {feature} - Importância: {importances_detractor[indices_detractor[i]]:.2f}")

  print("\nGráficos PDP para o modelo de detratores:")
  gerarPDP(model_detractor, X_train_detractor, feature_names)
  print("\n\n\n")


  importances_Neutral = model_neutral.feature_importances_
  indices_Neutral = np.argsort(importances_Neutral)[::-1][:10]
  top_10_features_Neutral = features_df.columns[indices_Neutral]
  print("\nTop 10 variáveis mais importantes para o modelo de neutros:")
  for i, feature in enumerate(top_10_features_Neutral):
    print(f"{i + 1}. {feature} - Importância: {importances_Neutral[indices_Neutral[i]]:.2f}")

  print("\nGráficos PDP para o modelo de neutros:")
  gerarPDP(model_neutral, X_train_neutral, feature_names)


def calcular_volumetria_safrada(safra):
    resultados = []

    for ano, dados in safra.items():
        total = len(dados)
        promotores = len(dados[dados['categoria'] == "Promotor"])
        neutros = len(dados[dados['categoria'] == "Neutro"])
        detratores = len(dados[dados['categoria'] == "Detrator"])

        resultados.append({
            'Safra': ano,
            'Total': total,
            'Promotores': promotores,
            'Neutros': neutros,
            'Detratores': detratores,
            '%Promotores': round((promotores / total) * 100, 1) if total > 0 else 0,
            '%Neutros': round((neutros / total) * 100, 1) if total > 0 else 0,
            '%Detratores': round((detratores / total) * 100, 1) if total > 0 else 0
        })

    # Soma de todas as safras
    total_geral = {
        'Safra': 'Total',
        'Total': sum(r['Total'] for r in resultados),
        'Promotores': sum(r['Promotores'] for r in resultados),
        'Neutros': sum(r['Neutros'] for r in resultados),
        'Detratores': sum(r['Detratores'] for r in resultados),
        '%Promotores': round((sum(r['Promotores'] for r in resultados) / sum(r['Total'] for r in resultados)) * 100, 1) if sum(r['Total'] for r in resultados) > 0 else 0,
        '%Neutros': round((sum(r['Neutros'] for r in resultados) / sum(r['Total'] for r in resultados)) * 100, 1) if sum(r['Total'] for r in resultados) > 0 else 0,
        '%Detratores': round((sum(r['Detratores'] for r in resultados) / sum(r['Total'] for r in resultados)) * 100, 1) if sum(r['Total'] for r in resultados) > 0 else 0
    }
    resultados.append(total_geral)

    return pd.DataFrame(resultados)



def calcular_volumetria_periodos(periodos_pesquisa):
    resultados = {}
    for periodo, dados in periodos_pesquisa.items():

        safra_periodo = criarSafra(dados)


        tabela_volumetria_periodo = calcular_volumetria_safrada(safra_periodo)


        resultados[periodo] = tabela_volumetria_periodo

    return resultados



def exibir_tabela_volumetria(tabela_volumetria, titulo="Volumetria Safrada"):
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.axis("tight")
    ax.axis("off")
    table = ax.table(
        cellText=tabela_volumetria.values,
        colLabels=tabela_volumetria.columns,
        cellLoc="center",
        loc="center",
        colLoc="center",
    )
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.auto_set_column_width(col=list(range(len(tabela_volumetria.columns))))
    plt.title(titulo, fontsize=12, pad=10)
    plt.show()




def exibir_tabelas_volumetria_periodos(volumetrias_por_periodo):
    for periodo, tabela in volumetrias_por_periodo.items():
        fig, ax = plt.subplots(figsize=(10, 4))
        ax.axis("tight")
        ax.axis("off")
        table = ax.table(
            cellText=tabela.values,
            colLabels=tabela.columns,
            cellLoc="center",
            loc="center",
            colLoc="center",
        )
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.auto_set_column_width(col=list(range(len(tabela.columns))))
        plt.title(f"Volumetria - Período: {periodo}", fontsize=12, pad=10)
        plt.show()

def correlacao_spearman(df_modelo, nome_df):

    def highlight_correlations(val):
        if 0.8 <= val <= 1.0:
            return 'background-color: red'
        elif 0.4 <= val < 0.8:
            return 'background-color: lightblue'
        elif val < 0.4:
            return 'background-color: lightgreen'
        return ''


    filtered_df = df_modelo


    numeric_filtered_df = filtered_df.select_dtypes(include=['number'])

    numeric_filtered_df = numeric_filtered_df.drop(columns=['target_neutral', 'target_detractor'], errors='ignore')

    spearman_corr_nota = numeric_filtered_df.corrwith(numeric_filtered_df['nota'], method='spearman')


    spearman_corr_nota_df = pd.DataFrame(spearman_corr_nota, columns=['Spearman Correlation with "nota"']).drop(index='nota')


    spearman_corr_nota_df_sorted = spearman_corr_nota_df.sort_values(by='Spearman Correlation with "nota"', ascending=False)


    spearman_corr_nota_df_sorted_clean = spearman_corr_nota_df_sorted.dropna()


    styled_corr_df_clean = spearman_corr_nota_df_sorted_clean.style.applymap(highlight_correlations)


    filename = f'correlacao_spearman_com_nota_{nome_df}.xlsx'
    styled_corr_df_clean.to_excel(filename)


    print("\n### CORRELAÇÃO DE SPEARMAN COM A COLUNA 'NOTA' ###\n")
    print(spearman_corr_nota_df_sorted_clean)


    return spearman_corr_nota_df_sorted_clean




def criarSafraCorrelacao(regiao_df, nome_df):

    def highlight_correlations(val):
        if 0.8 <= val <= 1.0:
            return 'background-color: red'
        elif 0.4 <= val < 0.8:
            return 'background-color: lightblue'
        elif val < 0.4:
            return 'background-color: lightgreen'
        return ''


    def calcular_correlacao_safra(df, ano):

        numeric_filtered_df = df.select_dtypes(include=['number'])


        numeric_filtered_df = numeric_filtered_df.drop(columns=['target_neutral', 'target_detrator'], errors='ignore')


        spearman_corr_nota = numeric_filtered_df.corrwith(numeric_filtered_df['nota'], method='spearman')


        spearman_corr_nota_df = pd.DataFrame(spearman_corr_nota, columns=['Spearman Correlation with "nota"']).drop(index='nota')


        spearman_corr_nota_df_sorted = spearman_corr_nota_df.sort_values(by='Spearman Correlation with "nota"', ascending=False)


        spearman_corr_nota_df_sorted_clean = spearman_corr_nota_df_sorted.dropna()


        styled_corr_df_clean = spearman_corr_nota_df_sorted_clean.style.applymap(highlight_correlations)


        filename = f'correlacao_spearman_com_nota_{nome_df}_safra_{ano}.xlsx'
        styled_corr_df_clean.to_excel(filename)


        print(f"\n### CORRELAÇÃO DE SPEARMAN COM A COLUNA 'NOTA' - SAFRA {ano} ###\n")
        print(spearman_corr_nota_df_sorted_clean)


        return spearman_corr_nota_df_sorted_clean


    safras = {
        2022: calcular_correlacao_safra(regiao_df[regiao_df['data_resposta'].dt.year == 2022], 2022),
        2023: calcular_correlacao_safra(regiao_df[regiao_df['data_resposta'].dt.year == 2023], 2023),
        2024: calcular_correlacao_safra(regiao_df[regiao_df['data_resposta'].dt.year == 2024], 2024),
    }


    return safras

"""# Etapa 1/Etapa 2/ Etapa 3

# Filtrando a tabela do excel, e atribuindo valores a cada avaliação de acordo com a nota(Promotor, Detrator e Neutro)
"""

df = pd.read_excel('Lista NPS Positivo_V4 (1).xlsx')


df_grupo1 = df[(df['Grupo de Produto'] == 'Grupo 1') & (df['mercado'] == 'BRASIL')]

df_grupo1['data_resposta'] = pd.to_datetime(df_grupo1['data_resposta'], format='%d/%m/%Y %H:%M:%S', errors = 'coerce')


def categorizar_nota(nota):
    if nota >= 9:
        return "Promotor"
    elif nota >= 7:
        return "Neutro"
    else:
        return "Detrator"


df_grupo1['categoria'] = df_grupo1['nota'].apply(categorizar_nota)


print(df_grupo1[['nota', 'categoria']])

"""# Etapa 4

# Calculando volumetria do target da base geral, incluindo a contagem e porcentagem de Detratores, Neutros e Promotores
"""

contagem_categorias = df_grupo1.groupby('categoria').size()


porcentagem_categorias = df_grupo1.groupby('categoria').size() / len(df_grupo1) * 100


resultado_categorias = pd.DataFrame({
    'Contagem': contagem_categorias,
    'Porcentagem (%)': porcentagem_categorias.round(2)
}).reset_index()


print(resultado_categorias)

"""# Etapa 5 - Região SUL"""

sul = df_grupo1[(df_grupo1['estado'] == 'PR') |
                (df_grupo1['estado'] == 'SC') |
                (df_grupo1['estado'] == 'RS')]



sul[['nota', 'categoria']]

safra_sul = criarSafra(sul)

mostrarSafra(safra_sul)

"""# Etapa 5 - Região NORTE"""

norte = df_grupo1[(df_grupo1['estado'] == 'RO') |
                  (df_grupo1['estado'] == 'AC') |
                  (df_grupo1['estado'] == 'AM') |
                  (df_grupo1['estado'] == 'RR') |
                  (df_grupo1['estado'] == 'PA') |
                  (df_grupo1['estado'] == 'TO') |
                  (df_grupo1['estado'] == 'AP')]


norte_selecionado = norte[['nota', 'categoria']]


print(norte_selecionado)

safra_norte = criarSafra(norte)

mostrarSafra(safra_norte)

"""# Etapa 5 - Região SUDESTE"""

sudeste = df_grupo1[(df_grupo1['estado'] == 'SP') |
                    (df_grupo1['estado'] == 'RJ') |
                    (df_grupo1['estado'] == 'MG') |
                    (df_grupo1['estado'] == 'ES')]


sudeste_selecionado = sudeste[['nota', 'categoria']]


print(sudeste_selecionado)

safra_sudeste = criarSafra(sudeste)

mostrarSafra(safra_sudeste)

"""# Etapa 5 - Região NORDESTE"""

nordeste = df_grupo1[(df_grupo1['estado'] == 'BA') |
                     (df_grupo1['estado'] == 'SE') |
                     (df_grupo1['estado'] == 'AL') |
                     (df_grupo1['estado'] == 'PE') |
                     (df_grupo1['estado'] == 'PB') |
                     (df_grupo1['estado'] == 'RN') |
                     (df_grupo1['estado'] == 'CE') |
                     (df_grupo1['estado'] == 'PI') |
                     (df_grupo1['estado'] == 'MA')]


nordeste_selecionado = nordeste[['nota', 'categoria']]


print(nordeste_selecionado)

safra_nordeste = criarSafra(nordeste)

mostrarSafra(safra_nordeste)

"""# Etapa 5 - Região CENTRO-OESTE"""

centro_oeste = df_grupo1[(df_grupo1['estado'] == 'MT')  |
                          (df_grupo1['estado'] == 'MS') |
                          (df_grupo1['estado'] == 'GO') |
                          (df_grupo1['estado'] == 'DF')]


centro_oeste_selecionado = centro_oeste[['nota', 'categoria']]


print(centro_oeste_selecionado)

safra_centro_oeste = criarSafra(centro_oeste)

mostrarSafra(safra_centro_oeste)

"""# Períodos de Pesquisa

# Criando variaveis de período de pesquisa
"""

periodos_pesquisa = {
    '3a6': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '3 a 6 M'],
    '6a12': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '6 a 12 M'],
    '12a18': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '12 a 18 M'],
    '18a30': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '18 a 30 M']
}


periodos_pesquisa['3a6'][['Periodo de Pesquisa', 'categoria', 'nota']]
periodos_pesquisa['6a12'][['Periodo de Pesquisa', 'categoria', 'nota']]
periodos_pesquisa['12a18'][['Periodo de Pesquisa', 'categoria', 'nota']]
periodos_pesquisa['18a30'][['Periodo de Pesquisa', 'categoria', 'nota']]

periodos_pesquisa['12a18'][['Periodo de Pesquisa', 'categoria', 'nota']]

periodos_pesquisa['6a12'][['Periodo de Pesquisa', 'categoria', 'nota']]

periodos_pesquisa['3a6'][['Periodo de Pesquisa', 'categoria', 'nota']]

"""# Etapa 6 - Criando Safra total

# Chamando a função criar safra, enviando todo o dataframe e retornando todas as safras da base(2022, 2023 e 2024)

# As safras por região estão na etapa 5 acima
"""

safraTotal = criarSafra(df_grupo1)

mostrarSafra(safraTotal)

"""# Etapa 7 - Cálculos da volumetria safrada/por região

"""

tabela_volumetria = calcular_volumetria_safrada(safraTotal)


print(tabela_volumetria)
print(df_grupo1.groupby('categoria').size())

tabela_volumetria_sul = calcular_volumetria_safrada(safra_sul)


print(tabela_volumetria_sul)

tabela_volumetria_norte = calcular_volumetria_safrada(safra_norte)
print(tabela_volumetria_norte)

"""# Etapa 7 - Cálculos da volumetria por períodos"""

periodos_pesquisa = {
    '3a6': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '3 a 6 M'],
    '6a12': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '6 a 12 M'],
    '12a18': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '12 a 18 M'],
    '18a30': df_grupo1[df_grupo1['Periodo de Pesquisa'] == '18 a 30 M']
}


volumetrias_por_periodo = calcular_volumetria_periodos(periodos_pesquisa)
print(volumetrias_por_periodo)

"""# Etapa 7 - Exibir tabelas de volumetria"""

exibir_tabelas_volumetria_periodos(volumetrias_por_periodo)

tabela_volumetria_safra = calcular_volumetria_safrada(safraTotal)


exibir_tabela_volumetria(tabela_volumetria_safra, titulo="Volumetria - Total")

tabela_volumetria_safra = calcular_volumetria_safrada(safra_sul)


exibir_tabela_volumetria(tabela_volumetria_safra, titulo="Volumetria - Região Sul")

tabela_volumetria_safra = calcular_volumetria_safrada(safra_sudeste)


exibir_tabela_volumetria(tabela_volumetria_safra, titulo="Volumetria - Região sudeste")

tabela_volumetria_safra = calcular_volumetria_safrada(safra_norte)


exibir_tabela_volumetria(tabela_volumetria_safra, titulo="Volumetria - Região Norte")

tabela_volumetria_safra = calcular_volumetria_safrada(safra_nordeste)


exibir_tabela_volumetria(tabela_volumetria_safra, titulo="Volumetria - Região Nordeste")

tabela_volumetria_safra = calcular_volumetria_safrada(safra_centro_oeste)


exibir_tabela_volumetria(tabela_volumetria_safra, titulo="Volumetria - Região Centro Oeste")

"""# Etapa 9"""

correlacao_spearman(df_grupo1, "safraTotal")
criarSafraCorrelacao(df_grupo1, "safraTotal")

correlacao_spearman(sul, "sul")
criarSafraCorrelacao(sul, "sul")

correlacao_spearman(norte, "norte")
criarSafraCorrelacao(norte, "norte")

correlacao_spearman(nordeste, "nordeste")
criarSafraCorrelacao(nordeste, "nordeste")

correlacao_spearman(sudeste, "sudeste")
criarSafraCorrelacao(sudeste, "sudeste")

correlacao_spearman(centro_oeste, "centro_oeste")
criarSafraCorrelacao(centro_oeste, "centro_oeste")

correlacao_spearman(periodos_pesquisa['3a6'], "3a6")
criarSafraCorrelacao(periodos_pesquisa['3a6'], "3a6")

correlacao_spearman(periodos_pesquisa['6a12'], "6a12")
criarSafraCorrelacao(periodos_pesquisa['6a12'], "6a12")

correlacao_spearman(periodos_pesquisa['12a18'], "12a18")
criarSafraCorrelacao(periodos_pesquisa['12a18'], "12a18")

correlacao_spearman(periodos_pesquisa['18a30'], "18a30")
criarSafraCorrelacao(periodos_pesquisa['18a30'], "18a30")

"""# Etapa 10 - Criando modelos de classificação"""

criarModelo(df_grupo1)

criarModelo(sul)

criarModelo(norte)

criarModelo(sudeste)

criarModelo(nordeste)

criarModelo(centro_oeste)

criarModelo(periodos_pesquisa['3a6'])

criarModelo(periodos_pesquisa['6a12'])

criarModelo(periodos_pesquisa['12a18'])

criarModelo(periodos_pesquisa['18a30'])

